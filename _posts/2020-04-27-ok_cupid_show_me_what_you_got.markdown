---
layout: post
title:      "Ok, Cupid.  Show me what you got."
date:       2020-04-27 09:35:16 +0000
permalink:  ok_cupid_show_me_what_you_got
---


![](https://thetiaramisu.files.wordpress.com/2020/04/okcupid-search.jpg)

[OkCupid](https://render.githubusercontent.com/view/www.okcupid.com) is an online dating website that was founded in 2004. A description of their matching process can be found on their [Wikipedia](https://en.wikipedia.org/wiki/OkCupid) page:

*"To generate matches, OkCupid applies data generated by users' activities on the site, as well as their answers to questions. When answering a question, a user indicates his or her own answer, the answers he or she would accept from partners, and the level of importance he or she places on the question. The results of these questions can be made public. OkCupid describes in detail the algorithm used to calculate match percentages. Assuming a user is a paid user ("A-List"), the site notifies a user if someone likes that user."*

My objective in this project was to form a model based off of OkCupid data to predict whether a user profile belongs to a male or a female. An analysis of the trends in profile responses given by gender could be beneficial in determining how the company can better accommodate their user base.

## The Data

![](https://thetiaramisu.files.wordpress.com/2020/04/download-7.png?w=646&h=364)

The dataset I used for this project was scraped on June 30th, 2012. It includes anonymized profile information for all active profiles at the time of the scrap within a 25-mile radius of San Francisco. Profiles were considered active if the account holder had logged in within the previous year and if they had at least one profile picture.

The dataset provides the answers provided by 59,946 active users for the different personal and preference questions asked by OkCupid when creating an online account. The full dataset can be found [here](https://github.com/rudeboybert/JSE_OkCupid), and the column descriptions are provided at [this link](https://github.com/rudeboybert/JSE_OkCupid/blob/master/okcupid_codebook.txt) on the same github.

The columns in the dataset represented information found for each profile entry, input by the person who made their profile. The columns were: age, body_type, diet, drinks, drugs, education, ethnicity, height, income, job, last_online, location, offspring, orientation, pets, religion, sex, sign, smokes, speaks, status. Additionally, there were 10 columns with typed responses to free response questions.

## Cleaning the Data

As I dug into the data, I found that it was extremely messy and there were numerous hiccups that I ran into. I learned through this process that such issues can be expected from datasets comprised entirely of user-input information. The values were subjective and inconsistent. Especially because the majority of the profile questions were optional, there were a large number of null values across most of the columns.

![](https://thetiaramisu.files.wordpress.com/2020/04/download-6.png)

![](https://thetiaramisu.files.wordpress.com/2020/04/download-5.png)

The essay questions were very intriguing, however, I quickly realized that each answer was capped at a certain character count. Because many of the answers were cut very short, these were sadly the first columns that had to be removed.

Another difficulty was the large number of options to select from for many of the questions, which I ended up simplifying. For example, under the pets preferences section, these were all the original option selections.

![](https://thetiaramisu.files.wordpress.com/2020/04/mod4-pets.png)

You can only imagine how much more complicated the sections were for religion and ethnicity!

## Modeling

My objective was to create a model that can determine whether an OkCupid profile belongs to a male or female user.

The features I was able to use for my model were: age, body type, diet, drinks, drug use, education, height, job, orientation, religion, sex, smokes, speaks, status, ethnicity (divided based on what each individual checked off, because many were multiethnic), cat preference, and dog preference. The preprocessing step of this project involved scaling and normalizing the continuous features,  and one hot encoding the categorical features.

I began the modeling by making a vanilla logistic regression as well as an XGBoost model. These were done to find a baseline to which I could compare my neural networks.

My logistic regression gave a training accuracy of 88.3% and a test accuracy of 88.11% and the XGBoost model gave a training accuracy of 87.91% and a test accuracy of 88.11%.

My focus in this project was to explore the ways that you can tune neural networks. I started with a baseline neural network model. I first tried my baseline model with 3 layers, and then with 4. The 4-layer neural network had slightly better results, so I decided to go with 4.

```
from keras import models, layers, optimizers, regularizers

model = models.Sequential()

model.add(layers.Dense(12, 
                       kernel_initializer='uniform', 
                       activation='relu', 
                       input_shape=(X_train.shape[1],)))
model.add(layers.Dense(6, activation='relu'))
model.add(layers.Dense(6, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
```

![](https://thetiaramisu.files.wordpress.com/2020/04/screen-shot-2020-04-09-at-3.29.08-am.jpg)

Building off of this baseline neural network, I tried a variety of methods to tune my model.

L2 Regularization: Also known as weight decay, the neural network introduced an additional penalty term at each layer to reduce variance. This method multiplied each weight by a regularized penalty that takes in sum over all the squared weight values of the weight matrix. The objective of this method is to decrease the impact of each weight during training to simplify the network.

L1 Regularization: This method sought a similar effect as L2 regularization, except that the penalty takes in the sum of the absolute values of the weight parameters in the weight matrix.

Dropout Regularization: As the network was trained, a randomly selected 30% of the nodes in each layer were given zero weight. In each iteration, the random selection varied. This trained the network in a way that spread out the impact of the weights, so that the network could not rely on any specific feature.

Stochastic Gradient Descent (SGD) Optimizer: SGD works similarly to gradient descent, however, instead of taking the gradient from the whole training set, it took the gradient only from a randomly selected subset in each iteration. The weights are updated and adjusted after each training instance. Because the subsets it is working with are smaller, each iteration with SGD occurs much more quickly, allowing for many more iterations to occur.

## Conclusions

The best predictor was the baseline neural network, providing a predictive accuracy of 88.31%.

The feature importance ranking results from the Logistic Regression and XGBoost shared these top factors in predicting sex:

* Height
* Body Type: Curvy, Full Figured, Thin
* Job: Construction/Craftsmanship, Computer/Hardware/Software, Science/Tech/Engineering

![](https://thetiaramisu.files.wordpress.com/2019/06/jobs-gender.png)

![](https://thetiaramisu.files.wordpress.com/2019/06/body-type-gender.png)

It is interesting that the top body type descriptors are more representative of the female users, and the top job descriptors are more representative of the male users.

![](https://thetiaramisu.files.wordpress.com/2020/04/height-gender.png)

As we saw in our t-test earlier, we can predict with over 99% confidence that males on OkCupid are taller than females on average. From our data, the difference between the mean male height (5'10") and the mean female height (5'4") is 6 inches.

Future Work
* Tune the models more after dropping features
* Do more research on ethnicity
* Gather data on factors that lead to profile visits and matches
* Get full essay answers to look for trends in what people write themselves

Thanks for reading! You can find my full project [here](https://github.com/thetiaramisu/dsc-4-final-project-online-ds-ft-011419).
